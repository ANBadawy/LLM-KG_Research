{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized function extracting Table of content from a TextBook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems:\n",
    "1. some table of content are images\n",
    "   - Use OCR\n",
    "2. some titles are different\n",
    "   - Use hugging face semantic similarity?\n",
    "3. How to know we are at the end of the table of content?\n",
    "   - Access the sections in a book? but how?\n",
    "4. I want it to extract the main nodes and lateral notes -> Dependency tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import sys\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(pdf_path):\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        \n",
    "        # Initialize an empty string to store the extracted text\n",
    "        extracted_text = ''\n",
    "        number_of_pages = 30                       ##\n",
    "\n",
    "        # Loop through each page and extract the text\n",
    "        for page_num in range(number_of_pages):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            page_text = page.extract_text()\n",
    "            extracted_text+=page_text\n",
    "       \n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start(all_extracted_text): \n",
    "    index = -1\n",
    "    words_to_find = [\"table of contents\", \"contents\", \"index\"]\n",
    "    for word in words_to_find:\n",
    "        start = all_extracted_text.lower().find(word)\n",
    "        if start != -1:\n",
    "            return start\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_end(all_extracted_text): \n",
    "    index = -1\n",
    "    words_to_find = [\"chapter 1\"]\n",
    "    for word in words_to_find:\n",
    "        end = all_extracted_text.lower().find(word)\n",
    "        if end != -1:\n",
    "            return end\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roughly_table_of_content(all_extracted_text):\n",
    "\n",
    "    start = find_start(all_extracted_text) \n",
    "    end = find_end(all_extracted_text)\n",
    "    \n",
    "    if start !=-1 and end != -1:\n",
    "        modified_text = all_extracted_text[start:end]\n",
    "        return modified_text\n",
    "    else:\n",
    "        return all_extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_path):\n",
    "    all_extracted_text = extraction(pdf_path)\n",
    "    filtered_text = roughly_table_of_content(all_extracted_text)\n",
    "   \n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE OF CONTENTS\n",
      "1. Probability of Events . . . . . . . . . . . . . . . . . . . 1\n",
      "1.1. Introduction\n",
      "1.2. Counting Techniques\n",
      "1.3. Probability Measure\n",
      "1.4. Some Properties of the Probability Measure\n",
      "1.5. Review Exercises\n",
      "2. Conditional Probability and Bayes’ Theorem . . . . . . . 27\n",
      "2.1. Conditional Probability\n",
      "2.2. Bayes’ Theorem\n",
      "2.3. Review Exercises\n",
      "3. Random Variables and Distribution Functions . . . . . . . 45\n",
      "3.1. Introduction\n",
      "3.2. Distribution Functions of Discrete Variables\n",
      "3.3. Distribution Functions of Continuous Variables\n",
      "3.4. Percentile for Continuous Random Variables\n",
      "3.5. Review Exercises\n",
      "4. Moments of Random Variables and Chebychev Inequality . 73\n",
      "4.1. Moments of Random Variables\n",
      "4.2. Expected Value of Random Variables\n",
      "4.3. Variance of Random Variables\n",
      "4.4. Chebychev Inequality\n",
      "4.5. Moment Generating Functions\n",
      "4.6. Review Exercisesxiii\n",
      "5. Some Special Discrete Distributions . . . . . . . . . . . 107\n",
      "5.1. Bernoulli Distribution\n",
      "5.2. Binomial Distribution\n",
      "5.3. Geometric Distribution\n",
      "5.4. Negative Binomial Distribution\n",
      "5.5. Hypergeometric Distribution\n",
      "5.6. Poisson Distribution\n",
      "5.7. Riemann Zeta Distribution\n",
      "5.8. Review Exercises\n",
      "6. Some Special Continuous Distributions . . . . . . . . . 141\n",
      "6.1. Uniform Distribution\n",
      "6.2. Gamma Distribution\n",
      "6.3. Beta Distribution\n",
      "6.4. Normal Distribution\n",
      "6.5. Lognormal Distribution\n",
      "6.6. Inverse Gaussian Distribution\n",
      "6.7. Logistic Distribution\n",
      "6.8. Review Exercises\n",
      "7. Two Random Variables . . . . . . . . . . . . . . . . . 185\n",
      "7.1. Bivariate Discrete Random Variables\n",
      "7.2. Bivariate Continuous Random Variables\n",
      "7.3. Conditional Distributions\n",
      "7.4. Independence of Random Variables\n",
      "7.5. Review Exercises\n",
      "8. Product Moments of Bivariate Random Variables . . . . 213\n",
      "8.1. Covariance of Bivariate Random Variables\n",
      "8.2. Independence of Random Variables\n",
      "8.3. Variance of the Linear Combination of Random Variables\n",
      "8.4. Correlation and Independence\n",
      "8.5. Moment Generating Functions\n",
      "8.6. Review Exercisesxiv\n",
      "9. Conditional Expectations of Bivariate Random Variables 237\n",
      "9.1. Conditional Expected Values\n",
      "9.2. Conditional Variance\n",
      "9.3. Regression Curve and Scedastic Curves\n",
      "9.4. Review Exercises\n",
      "10. Functions of Random Variables and Their Distribution . 257\n",
      "10.1. Distribution Function Method\n",
      "10.2. Transformation Method for Univariate Case\n",
      "10.3. Transformation Method for Bivariate Case\n",
      "10.4. Convolution Method for Sums of Random Variables\n",
      "10.5. Moment Method for Sums of Random Variables\n",
      "10.6. Review Exercises\n",
      "11. Some Special Discrete Bivariate Distributions . . . . . 289\n",
      "11.1. Bivariate Bernoulli Distribution\n",
      "11.2. Bivariate Binomial Distribution\n",
      "11.3. Bivariate Geometric Distribution\n",
      "11.4. Bivariate Negative Binomial Distribution\n",
      "11.5. Bivariate Hypergeometric Distribution\n",
      "11.6. Bivariate Poisson Distribution\n",
      "11.7. Review Exercises\n",
      "12. Some Special Continuous Bivariate Distributions . . . . 317\n",
      "12.1. Bivariate Uniform Distribution\n",
      "12.2. Bivariate Cauchy Distribution\n",
      "12.3. Bivariate Gamma Distribution\n",
      "12.4. Bivariate Beta Distribution\n",
      "12.5. Bivariate Normal Distribution\n",
      "12.6. Bivariate Logistic Distribution\n",
      "12.7. Review Exercisesxv\n",
      "13. Sequences of Random Variables and Order Statistics . . 353\n",
      "13.1. Distribution of Sample Mean and Variance\n",
      "13.2. Laws of Large Numbers\n",
      "13.3. The Central Limit Theorem\n",
      "13.4. Order Statistics\n",
      "13.5. Sample Percentiles\n",
      "13.6. Review Exercises\n",
      "14. Sampling Distributions Associated with\n",
      "the Normal Population . . . . . . . . . . . . . . . . . 395\n",
      "14.1. Chi-square distribution\n",
      "14.2. Student’s t-distribution\n",
      "14.3. Snedecor’s F-distribution\n",
      "14.4. Review Exercises\n",
      "15. Some Techniques for Finding Point\n",
      "Estimators of Parameters . . . . . . . . . . . . . . . 413\n",
      "15.1. Moment Method\n",
      "15.2. Maximum Likelihood Method\n",
      "15.3. Bayesian Method\n",
      "15.3. Review Exercises\n",
      "16. Criteria for Evaluating the Goodness\n",
      "of Estimators . . . . . . . . . . . . . . . . . . . . . 455\n",
      "16.1. The Unbiased Estimator\n",
      "16.2. The Relatively E ﬃcient Estimator\n",
      "16.3. The Minimum Variance Unbiased Estimator\n",
      "16.4. Su ﬃcient Estimator\n",
      "16.5. Consistent Estimator\n",
      "16.6. Review Exercisesxvi\n",
      "17. Some Techniques for Finding Interval\n",
      "Estimators of Parameters . . . . . . . . . . . . . . . 497\n",
      "17.1. Interval Estimators and Conﬁdence Intervals for Parameters\n",
      "17.2. Pivotal Quantity Method\n",
      "17.3. Conﬁdence Interval for Population Mean\n",
      "17.4. Conﬁdence Interval for Population Variance\n",
      "17.5. Conﬁdence Interval for Parameter of some Distributions\n",
      "not belonging to the Location-Scale Family\n",
      "17.6. Approximate Conﬁdence Interval for Parameter with MLE\n",
      "17.7. The Statistical or General Method\n",
      "17.8. Criteria for Evaluating Conﬁdence Intervals\n",
      "17.9. Review Exercises\n",
      "18. Test of Statistical Hypotheses . . . . . . . . . . . . . 541\n",
      "18.1. Introduction\n",
      "18.2. A Method of Finding Tests\n",
      "18.3. Methods of Evaluating Tests\n",
      "18.4. Some Examples of Likelihood Ratio Tests\n",
      "18.5. Review Exercises\n",
      "19. Simple Linear Regression and Correlation Analysis . . 585\n",
      "19.1. Least Squared Method\n",
      "19.2. Normal Regression Analysis\n",
      "19.3. The Correlation Analysis\n",
      "19.4. Review Exercises\n",
      "20. Analysis of Variance . . . . . . . . . . . . . . . . . . 621\n",
      "20.1. One-way Analysis of Variance with Equal Sample Sizes\n",
      "20.2. One-way Analysis of Variance with Unequal Sample Sizes\n",
      "20.3. Pair wise Comparisons\n",
      "20.4. Tests for the Homogeneity of Variances\n",
      "20.5. Review Exercisesxvii\n",
      "21. Goodness of Fits Tests . . . . . . . . . . . . . . . . . 653\n",
      "21.1. Chi-Squared test\n",
      "21.2. Kolmogorov-Smirnov test\n",
      "21.3. Review Exercises\n",
      "References . . . . . . . . . . . . . . . . . . . . . . . . . 671\n",
      "Answers to Selected Review Exercises . . . . . . . . . . . 677Probability and Mathematical Statistics 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "book_name = \"book2.pdf\"\n",
    "book_file_path = os.path.join( \"..\", \"books\", book_name)\n",
    "print(pdf_to_text(book_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OCR when we have a book that is an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big data, machine learning, and more, using Python tools\n",
      "\n",
      "Davy Cielen\n",
      "Arno D. B. Meysman\n",
      "Mohamed Ali\n",
      "\n",
      "i MANNING\n",
      "\n",
      "Introducing Data Science\n",
      "Introducing\n",
      "Data Science\n",
      "\n",
      "BIG DATA, MACHINE LEARNING,\n",
      "AND MORE, USING PYTHON TOOLS\n",
      "\n",
      "DAVY CIELEN\n",
      "ARNO D. B. MEYSMAN\n",
      "MOHAMED ALI\n",
      "\n",
      "MANNING\n",
      "SHELTER ISLAND\n",
      "For online information and ordering of this and other Manning books, please visit\n",
      "www.manning.com. The publisher offers discounts on this book when ordered in quantity.\n",
      "For more information, please contact\n",
      "\n",
      "Special Sales Department\n",
      "Manning Publications Co.\n",
      "\n",
      "20 Baldwin Road\n",
      "\n",
      "PO Box 761\n",
      "\n",
      "Shelter Island, NY 11964\n",
      "Email: orders@manning.com\n",
      "\n",
      "©2016 by Manning Publications Co. All rights reserved.\n",
      "\n",
      "No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in\n",
      "any form or by means electronic, mechanical, photocopying, or otherwise, without prior written\n",
      "permission of the publisher.\n",
      "\n",
      "Many of the designations used by manufacturers and sellers to distinguish their products are\n",
      "claimed as trademarks. Where those designations appear in the book, and Manning\n",
      "Publications was aware of a trademark claim, the designations have been printed in initial caps\n",
      "or all caps.\n",
      "\n",
      "Recognizing the importance of preserving what has been written, it is Manning’s policy to have\n",
      "the books we publish printed on acid-free paper, and we exert our best efforts to that end.\n",
      "Recognizing also our responsibility to conserve the resources of our planet, Manning books\n",
      "are printed on paper that is at least 15 percent recycled and processed without the use of\n",
      "elemental chlorine.\n",
      "\n",
      "Manning Publications Co.\n",
      "20 Baldwin Road\n",
      "\n",
      "PO Box 761\n",
      "\n",
      "Shelter Island, NY 11964\n",
      "\n",
      "Technical proofreader:\n",
      "\n",
      "Typesetter:\n",
      "Cover designer:\n",
      "\n",
      "ISBN: 9781633430037\n",
      "Printed in the United States of America\n",
      "123456789 10 - EBM - 21 20 19 18 17 16\n",
      "\n",
      "Development editor:\n",
      "\n",
      "Technical development editors:\n",
      "Copyeditor:\n",
      "\n",
      "Proofreader:\n",
      "\n",
      "Dan Maharry\n",
      "\n",
      "Michael Roberts, Jonathan Thoms\n",
      "Katie Petito\n",
      "\n",
      "Alyson Brener\n",
      "\n",
      "Ravishankar Rajagopalan\n",
      "\n",
      "Dennis Dalinnik\n",
      "\n",
      "Marija Tudor\n",
      "brief contents\n",
      "\n",
      "© MN DA KR WH RK\n",
      "\n",
      "Data science in a big data world 1\n",
      "\n",
      "The data science process 22\n",
      "\n",
      "Machine learning 57\n",
      "\n",
      "Handling large data on a single computer 85\n",
      "First steps in big data 119\n",
      "\n",
      "Join the NoSQL movement 150\n",
      "\n",
      "The rise of graph databases 190\n",
      "\n",
      "Text mining and text analytics 218\n",
      "\n",
      "Data visualization to the end user 253\n",
      "contents\n",
      "\n",
      "preface xiii\n",
      "\n",
      "acknowledgments xiv\n",
      "\n",
      "about this book xvi\n",
      "\n",
      "about the authors xviii\n",
      "\n",
      "about the cover illustration xx\n",
      "\n",
      "Data science in a big data world 1\n",
      "\n",
      "1.1 Benefits and uses of data science and big data 2\n",
      "1.2 Facetsofdata 4\n",
      "\n",
      "Structured data 4 = Unstructured data 5\n",
      "\n",
      "Natural language 5 * Machine-generated data 6\n",
      "\n",
      "Graph-based or network data 7 = Audio, image, and video 8\n",
      "Streaming data 8\n",
      "\n",
      "1.3. The data science process 8\n",
      "\n",
      "Setting the research goal 8 = Retrieving data 9\n",
      "Data preparation 9 = Data exploration 9\n",
      "\n",
      "Data modeling or model building 9 = Presentation\n",
      "and automation 9\n",
      "\n",
      "1.4 The big data ecosystem and data science 10\n",
      "\n",
      "Distributed file systems 10 * Distributed programming\n",
      "framework 12 = Data integration framework 12\n",
      "viii CONTENTS\n",
      "\n",
      "Machine learning frameworks 12\" NoSQUL databases 13\n",
      "Scheduling tools 14 = Benchmarking tools 14\n",
      "System deployment 14 * Service programming 14\n",
      "Security 14\n",
      "\n",
      "1.5 An introductory working example of Hadoop 15\n",
      "\n",
      "1.6 Summary 20\n",
      "\n",
      "The data science process 22\n",
      "\n",
      "2.1 Overview of the data science process 22\n",
      "\n",
      "Don’t be a slave to the process 25\n",
      "\n",
      "2.2 Step 1: Defining research goals and creating\n",
      "a project charter 25\n",
      "Spend time understanding the goals and context of your research 26\n",
      "Create a project charter 26\n",
      "\n",
      "2.3. Step 2: Retrieving data 27\n",
      "Start with data stored within the company 28 * Don’t be afraid\n",
      "to shop around 28 = Do data quality checks now to prevent\n",
      "problems later 29\n",
      "\n",
      "2.4 Step 3: Cleansing, integrating, and transforming data 29\n",
      "Cleansing data 30 * Correct errors as early as possible 36\n",
      "Combining data from different data sources 37\n",
      "Transforming data 40\n",
      "\n",
      "2.5 Step 4: Exploratory data analysis 43\n",
      "\n",
      "2.6 Step 5: Build the models 48\n",
      "Model and variable selection 48 = Model execution 49\n",
      "Model diagnostics and model comparison 54\n",
      "\n",
      "2.7 Step 6: Presenting findings and building applications on\n",
      "top of them 55\n",
      "\n",
      "2.8 Summary 56\n",
      "\n",
      "Machine learning 57\n",
      "3.1 What is machine learning and why should you care\n",
      "about it? 58\n",
      "\n",
      "Applications for machine learning in data science 58\n",
      "Where machine learning is used in the data science process 59\n",
      "Python tools used in machine learning 60\n",
      "CONTENTS\n",
      "\n",
      "3.2. The modeling process 62\n",
      "Engineering features and selecting a model 62 Training\n",
      "your model 64\" Validating a model 64 *® Predicting\n",
      "new observations 65\n",
      "3.3 Types of machine learning 65\n",
      "Supervised learning 66 = Unsupervised learning 72\n",
      "3.4 Semi-supervised learning 82\n",
      "\n",
      "3.5 Summary 83\n",
      "\n",
      "Handling large data on a single computer 85\n",
      "4.1 The problems you face when handling large data 86\n",
      "\n",
      "4.2. General techniques for handling large volumes of data 87\n",
      "Choosing the right algorithm 88 * Choosing the right data\n",
      "structure 96 * Selecting the right tools 99\n",
      "\n",
      "4.3 General programming tips for dealing with\n",
      "large data sets 101\n",
      "Don't reinvent the wheel 101 © Get the most out of your\n",
      "hardware 102 = Reduce your computing needs 102\n",
      "\n",
      "4.4 Case study 1: Predicting malicious URLs 103\n",
      "\n",
      "Step 1: Defining the research goal 104 * Step 2: Acquiring\n",
      "the URL data 104 = Step 4: Data exploration 105\n",
      "Step 5: Model building 106\n",
      "\n",
      "4.5 Case study 2: Building a recommender system inside\n",
      "adatabase 108\n",
      "Tools and techniques needed 108 * Step 1: Research\n",
      "question 111 = Step 3: Data preparation 111\n",
      "\n",
      "Step 5: Model building 115 = Step 6: Presentation\n",
      "and automation 116\n",
      "\n",
      "4.6 Summary 118\n",
      "\n",
      "First steps in big data 119\n",
      "5.1 Distributing data storage and processing with\n",
      "frameworks 120\n",
      "\n",
      "Hadoop: a framework for storing and processing large data sets 121\n",
      "Spark: replacing MapReduce for better performance 123\n",
      "\n",
      "ix\n",
      "CONTENTS\n",
      "\n",
      "5.2 Case study: Assessing risk when loaning money 125\n",
      "Step 1: The research goal 126 = Step 2: Data retrieval 127\n",
      "\n",
      "Step 3: Data preparation 131 * Step 4: Data exploration &\n",
      "Step 6: Report building 135\n",
      "\n",
      "5.3. Summary 149\n",
      "\n",
      "6 Join the NoSQL movement 150\n",
      "\n",
      "6.1 Introduction to NoSQL_ 153\n",
      "\n",
      "ACID: the core principle of relational databases 153\n",
      "CAP Theorem: the problem with DBs on many nodes 154\n",
      "The BASE principles of NoSQL databases 156\n",
      "NoSQL database types 158\n",
      "6.2 Case study: What disease is that? 164\n",
      "Step 1: Setting the research goal 166 * Steps 2 and 3: Data\n",
      "retrieval and preparation 167 = Step 4: Data exploration 175\n",
      "Step 3 revisited: Data preparation for disease profiling 183\n",
      "\n",
      "Step 4 revisited: Data exploration for disease profiling 187\n",
      "Step 6: Presentation and automation 188\n",
      "\n",
      "6.3. Summary 189\n",
      "\n",
      "The rise of graph databases 190\n",
      "\n",
      "7.1 Introducing connected data and graph databases 191\n",
      "Why and when should I use a graph database? 193\n",
      "\n",
      "7.2. Introducing Neo4j: a graph database 196\n",
      "Cypher: a graph query language 198\n",
      "\n",
      "7.3. Connected data example: a recipe recommendation\n",
      "engine 204\n",
      "Step 1: Setting the research goal 205 * Step 2: Data retrieval 206\n",
      "\n",
      "Step 3: Data preparation 207 = Step 4: Data exploration 210\n",
      "Step 5: Data modeling 212 = Step 6: Presentation 216\n",
      "\n",
      "7.4 Summary 216\n",
      "\n",
      "Text mining and text analytics 218\n",
      "8.1 Text mining in the real world 220\n",
      "\n",
      "8.2 Text mining techniques 225\n",
      "\n",
      "Bag of words 225 = Stemming and lemmatization 227\n",
      "Decision tree classifier 228\n",
      "8.3\n",
      "\n",
      "8.4\n",
      "\n",
      "CONTENTS\n",
      "\n",
      "Case study: Classifying Reddit posts 230\n",
      "Meet the Natural Language Toolkit 231 = Data science process\n",
      "overview and step 1: The research goal 233 = Step 2: Data\n",
      "retrieval 234 = Step 3: Data preparation 237 * Step 4:\n",
      "Data exploration 240 = Step 3 revisited: Data preparation\n",
      "adapted 242 * Step 5: Data analysis 246 * Step 6:\n",
      "Presentation and automation 250\n",
      "\n",
      "Summary 252\n",
      "\n",
      "Data visualization to the end user 253\n",
      "\n",
      "9.1\n",
      "9.2\n",
      "\n",
      "9.3\n",
      "9.4\n",
      "9.5\n",
      "\n",
      "appendix A\n",
      "appendix B\n",
      "appendix C\n",
      "appendix D\n",
      "\n",
      "Data visualization options 254\n",
      "Crossfilter, the JavaScript MapReduce library 257\n",
      "\n",
      "Setting up everything 258 = Unleashing Crossfilter to filter the\n",
      "medicine data set 262\n",
      "\n",
      "Creating an interactive dashboard with dc.js_ 267\n",
      "Dashboard development tools 272\n",
      "Summary 273\n",
      "\n",
      "Setting up Elasticsearch 275\n",
      "\n",
      "Setting up Neo4j 281\n",
      "\n",
      "Installing MySQL server 284\n",
      "\n",
      "Setting up Anaconda with a virtual environment 288\n",
      "\n",
      "index 291\n",
      "preface\n",
      "\n",
      "It’s in all of us. Data science is what makes us humans what we are today. No, not the\n",
      "computer-driven data science this book will introduce you to, but the ability of our\n",
      "brains to see connections, draw conclusions from facts, and learn from our past expe-\n",
      "riences. More so than any other species on the planet, we depend on our brains for\n",
      "survival; we went all-in on these features to earn our place in nature. That strategy has\n",
      "worked out for us so far, and we’re unlikely to change it in the near future.\n",
      "\n",
      "But our brains can only take us so far when it comes to raw computing. Our biol-\n",
      "ogy can’t keep up with the amounts of data we can capture now and with the extent of\n",
      "our curiosity. So we turn to machines to do part of the work for us: to recognize pat-\n",
      "terns, create connections, and supply us with answers to our numerous questions.\n",
      "\n",
      "The quest for knowledge is in our genes. Relying on computers to do part of the\n",
      "job for us is not—but it is our destiny.\n",
      "\n",
      "xiii\n",
      "acknowledgments\n",
      "\n",
      "A big thank you to all the people of Manning involved in the process of making this\n",
      "book for guiding us all the way through.\n",
      "\n",
      "Our thanks also go to Ravishankar Rajagopalan for giving the manuscript a full\n",
      "technical proofread, and to Jonathan Thoms and Michael Roberts for their expert\n",
      "comments. There were many other reviewers who provided invaluable feedback\n",
      "throughout the process: Alvin Raj, Arthur Zubarev, Bill Martschenko, Craig Smith,\n",
      "Filip Pravica, Hamideh Iraj, Heather Campbell, Hector Cuesta, Ian Stirk, Jeff Smith,\n",
      "Joel Kotarski, Jonathan Sharley, Jorn Dinkla, Marius Butuc, Matt R. Cole, Matthew\n",
      "Heck, Meredith Godar, Rob Agle, Scott Chaussee, and Steve Rogers.\n",
      "\n",
      "First and foremost I want to thank my wife Filipa for being my inspiration and motiva-\n",
      "tion to beat all difficulties and for always standing beside me throughout my career\n",
      "and the writing of this book. She has provided me the necessary time to pursue my\n",
      "goals and ambition, and shouldered all the burdens of taking care of our little daugh-\n",
      "ter in my absence. I dedicate this book to her and really appreciate all the sacrifices\n",
      "she has made in order to build and maintain our little family.\n",
      "\n",
      "I also want to thank my daughter Eva, and my son to be born, who give me a great\n",
      "sense of joy and keep me smiling. They are the best gifts that God ever gave to my life and\n",
      "also the best children a dad could hope for: fun, loving, and always a joy to be with.\n",
      "\n",
      "A special thank you goes to my parents for their support over the years. Without\n",
      "the endless love and encouragement from my family, I would not have been able to\n",
      "finish this book and continue the journey of achieving my goals in life.\n",
      "ACKNOWLEDGMENTS xv\n",
      "\n",
      "I'd really like to thank all my coworkers in my company, especially Mo and Arno,\n",
      "for all the adventures we have been through together. Mo and Arno have provided me\n",
      "excellent support and advice. I appreciate all of their time and effort in making this\n",
      "book complete. They are great people, and without them, this book may not have\n",
      "been written.\n",
      "\n",
      "Finally, a sincere thank you to my friends who support me and understand that I\n",
      "do not have much time but I still count on the love and support they have given me\n",
      "throughout my career and the development of this book.\n",
      "\n",
      "DAVY CIELEN\n",
      "\n",
      "I would like to give thanks to my family and friends who have supported me all the way\n",
      "through the process of writing this book. It has not always been easy to stay at home\n",
      "writing, while I could be out discovering new things. I want to give very special thanks\n",
      "to my parents, my brother Jago, and my girlfriend Delphine for always being there for\n",
      "me, regardless of what crazy plans I come up with and execute.\n",
      "\n",
      "I would also like to thank my godmother, and my godfather whose current struggle\n",
      "with cancer puts everything in life into perspective again.\n",
      "\n",
      "Thanks also go to my friends for buying me beer to distract me from my work and\n",
      "to Delphine’s parents, her brother Karel, and his soon-to-be wife Tess for their hospi-\n",
      "tality (and for stuffing me with good food).\n",
      "\n",
      "All of them have made a great contribution to a wonderful life so far.\n",
      "\n",
      "Last but not least, I would like to thank my coauthor Mo, my ERC-homie, and my\n",
      "coauthor Davy for their insightful contributions to this book. I share the ups and\n",
      "downs of being an entrepreneur and data scientist with both of them on a daily basis.\n",
      "It has been a great trip so far. Let’s hope there are many more days to come.\n",
      "\n",
      "ARNO D. B. MEYSMAN\n",
      "\n",
      "First and foremost, I would like to thank my fiancée Muhuba for her love, understand-\n",
      "ing, caring, and patience. Finally, I owe much to Davy and Arno for having fun and for\n",
      "making an entrepreneurial dream come true. Their unfailing dedication has been a\n",
      "vital resource for the realization of this book.\n",
      "\n",
      "MOHAMED ALI\n",
      "about this book\n",
      "\n",
      "I can only show you the door. You’re the one that has to walk through it.\n",
      "\n",
      "Morpheus, The Matrix\n",
      "\n",
      "Welcome to the book! When reading the table of contents, you probably noticed\n",
      "the diversity of the topics we’re about to cover. The goal of Introducing Data Science\n",
      "is to provide you with a little bit of everything—enough to get you started. Data sci-\n",
      "ence is a very wide field, so wide indeed that a book ten times the size of this one\n",
      "wouldn’t be able to cover it all. For each chapter, we picked a different aspect we\n",
      "find interesting. Some hard decisions had to be made to keep this book from col-\n",
      "lapsing your bookshelf!\n",
      "\n",
      "We hope it serves as an entry point—your doorway into the exciting world of\n",
      "data science.\n",
      "\n",
      "Roadmap\n",
      "\n",
      "Chapters 1 and 2 offer the general theoretical background and framework necessary\n",
      "to understand the rest of this book:\n",
      "\n",
      "= Chapter | is an introduction to data science and big data, ending with a practi-\n",
      "cal example of Hadoop.\n",
      "\n",
      "= Chapter 2 is all about the data science process, covering the steps present in\n",
      "almost every data science project.\n",
      "ABOUT THIS BOOK xvii\n",
      "\n",
      "In chapters 3 through 5, we apply machine learning on increasingly large data sets:\n",
      "\n",
      "= Chapter 3 keeps it small. The data still fits easily into an average computer’s\n",
      "memory.\n",
      "\n",
      "= Chapter 4 increases the challenge by looking at “large data.” This data fits on\n",
      "your machine, but fitting it into RAM is hard, making it a challenge to process\n",
      "without a computing cluster.\n",
      "\n",
      "= Chapter 5 finally looks at big data. For this we can’t get around working with\n",
      "multiple computers.\n",
      "\n",
      "Chapters 6 through 9 touch on several interesting subjects in data science in a more-\n",
      "or-less independent matter:\n",
      "\n",
      "= Chapter 6 looks at NoSQL and how it differs from the relational databases.\n",
      "\n",
      "= Chapter 7 applies data science to streaming data. Here the main problem is not\n",
      "size, but rather the speed at which data is generated and old data becomes\n",
      "obsolete.\n",
      "\n",
      "= Chapter 8 is all about text mining. Not all data starts off as numbers. Text min-\n",
      "ing and text analytics become important when the data is in textual formats\n",
      "such as emails, blogs, websites, and so on.\n",
      "\n",
      "= Chapter 9 focuses on the last part of the data science process—data visualization\n",
      "and prototype application building—by introducing a few useful HTML5 tools.\n",
      "\n",
      "Appendixes A-D cover the installation and setup of the Elasticsearch, Neo4j, and\n",
      "MySQL databases described in the chapters and of Anaconda, a Python code package\n",
      "that's especially useful for data science.\n",
      "\n",
      "Whom this book is for\n",
      "\n",
      "This book is an introduction to the field of data science. Seasoned data scientists will\n",
      "see that we only scratch the surface of some topics. For our other readers, there are\n",
      "some prerequisites for you to fully enjoy the book. A minimal understanding of SQL,\n",
      "Python, HTML5, and statistics or machine learning is recommended before you dive\n",
      "into the practical examples.\n",
      "\n",
      "Code conventions and downloads\n",
      "\n",
      "We opted to use the Python script for the practical examples in this book. Over the\n",
      "past decade, Python has developed into a much respected and widely used data sci-\n",
      "ence language.\n",
      "\n",
      "The code itself is presented in a fixed-width font like this to separate it from\n",
      "ordinary text. Code annotations accompany many of the listings, highlighting impor-\n",
      "tant concepts.\n",
      "\n",
      "The book contains many code examples, most of which are available in the online\n",
      "code base, which can be found at the book’s website, https://www.manning.com/\n",
      "books/introducing-data-science.\n",
      "about the authors\n",
      "\n",
      "DAVy CIELEN is an experienced entrepreneur, book author, and\n",
      "professor. He is the co-owner with Arno and Mo of Optimately\n",
      "and Maiton, two data science companies based in Belgium and\n",
      "the UK, respectively, and co-owner of a third data science com-\n",
      "pany based in Somaliland. The main focus of these companies is\n",
      "on strategic big data science, and they are occasionally consulted\n",
      "by many large companies. Davy is an adjunct professor at the\n",
      "IESEG School of Management in Lille, France, where he is\n",
      "involved in teaching and research in the field of big data science.\n",
      "\n",
      "ARNO MEYSMAN is a driven entrepreneur and data scientist. He is\n",
      "the co-owner with Davy and Mo of Optimately and Maiton, two\n",
      "data science companies based in Belgium and the UK, respec-\n",
      "tively, and co-owner of a third data science company based in\n",
      "Somaliland. The main focus of these companies is on strategic\n",
      "big data science, and they are occasionally consulted by many\n",
      "large companies. Arno is a data scientist with a wide spectrum of\n",
      "interests, ranging from medical analysis to retail to game analytics.\n",
      "He believes insights from data combined with some imagination\n",
      "can go a long way toward helping us to improve this world.\n",
      "\n",
      "xviii\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def convert_pdf_to_img(pdf_file, max_pages=20):\n",
    "    images = convert_from_path(pdf_file, poppler_path=r\"./poppler/poppler-23.08.0/Library/bin\", first_page=0, last_page=max_pages - 1)\n",
    "    return images\n",
    "\n",
    "def convert_image_to_text(file):\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:/Users/Mariam Barakat/AppData/Local/Programs/Tesseract-OCR/tesseract.exe'\n",
    "    text = pytesseract.image_to_string(file)\n",
    "    return text\n",
    "\n",
    "def get_text_from_first_20_pages(pdf_file):\n",
    "    images = convert_pdf_to_img(pdf_file)\n",
    "    final_text = \"\"\n",
    "    for img in images:\n",
    "        out = convert_image_to_text(img)\n",
    "        final_text += out\n",
    "    return final_text\n",
    "\n",
    "pdf_file_path = \"../book1.pdf\"\n",
    "text_from_first_20_pages = get_text_from_first_20_pages(pdf_file_path)\n",
    "print(text_from_first_20_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
