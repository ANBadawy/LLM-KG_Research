{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad863a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in d:\\anaconda\\lib\\site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in d:\\anaconda\\lib\\site-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from fitz) (1.4.2)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from fitz) (1.7.3)\n",
      "Requirement already satisfied: configparser in d:\\anaconda\\lib\\site-packages (from fitz) (6.0.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from fitz) (1.21.6)\n",
      "Requirement already satisfied: pyxnat in d:\\anaconda\\lib\\site-packages (from fitz) (1.6)\n",
      "Requirement already satisfied: nibabel in d:\\anaconda\\lib\\site-packages (from fitz) (5.1.0)\n",
      "Requirement already satisfied: httplib2 in d:\\anaconda\\lib\\site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nipype in d:\\anaconda\\lib\\site-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\anaconda\\lib\\site-packages (from httplib2->fitz) (3.0.4)\n",
      "Requirement already satisfied: packaging>=17 in d:\\anaconda\\lib\\site-packages (from nibabel->fitz) (21.3)\n",
      "Requirement already satisfied: pydot>=1.2.3 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (1.4.2)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (7.0.0)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: prov>=1.5.2 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (2.0.0)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: click>=6.6.0 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (8.0.4)\n",
      "Requirement already satisfied: looseversion in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (2.7.1)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (3.19.1)\n",
      "Requirement already satisfied: filelock>=3.0.0 in d:\\anaconda\\lib\\site-packages (from nipype->fitz) (3.6.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click>=6.6.0->nipype->fitz) (0.4.4)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from etelemetry>=0.2.0->nipype->fitz) (2.27.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in d:\\anaconda\\lib\\site-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: lxml>=3.3.5 in d:\\anaconda\\lib\\site-packages (from prov>=1.5.2->nipype->fitz) (4.8.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in d:\\anaconda\\lib\\site-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas->fitz) (2021.3)\n",
      "Requirement already satisfied: future>=0.16 in d:\\anaconda\\lib\\site-packages (from pyxnat->fitz) (0.18.2)\n",
      "Requirement already satisfied: pathlib>=1.0 in d:\\anaconda\\lib\\site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (1.26.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a622ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in d:\\anaconda\\lib\\site-packages (1.22.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6935ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in d:\\anaconda\\lib\\site-packages (from PyPDF2) (4.1.1)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5035801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: D:\\CIS Intern\\Books\\(Adaptive Computation and Machine Learning series) Ian Goodfellow, Yoshua Bengio, Aaron Courville - Deep Learning-The MIT Press (2016).pdf\n",
      "Processing: D:\\CIS Intern\\Books\\Dive into Deep Learning Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola.pdf\n",
      "Processing: D:\\CIS Intern\\Books\\Hands_on_Machine_Learning_with_Scikit_Le.pdf\n",
      "Filtered data has been saved to D:/CIS Intern/Books/filtered_data.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def scrap_toc(filename):\n",
    "    doc = fitz.open(filename)\n",
    "    toc = doc.get_toc()\n",
    "    # Remove page numbers\n",
    "    res = [[item[0], item[1]] + item[3:] for item in toc]\n",
    "    # Remove useless tags\n",
    "    filtered_data = [item for item in res if item[1] not in ['Contents', 'Notation']]\n",
    "    return filtered_data\n",
    "\n",
    "def process_pdfs_in_folder(input_folder, supported_extensions, output_file):\n",
    "    # List to store all filtered data\n",
    "    all_filtered_data = []\n",
    "\n",
    "    # Loop through files in the input folder\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for filename in files:\n",
    "            if any(filename.lower().endswith(ext) for ext in supported_extensions):\n",
    "                full_path = os.path.join(root, filename)\n",
    "                print(\"Processing:\", full_path)\n",
    "\n",
    "                # Extract book name from filename\n",
    "                book_name = os.path.splitext(filename)[0]\n",
    "\n",
    "                # Add a newline before adding a new book entry\n",
    "                if all_filtered_data:\n",
    "                    all_filtered_data.append(\"\")  # Add an empty line\n",
    "\n",
    "                # Call scrap_toc function to get filtered data\n",
    "                filtered_data = scrap_toc(full_path)\n",
    "\n",
    "                # Create a new entry for the book title\n",
    "                new_entry = f\"Book Title: {book_name}\"\n",
    "\n",
    "                # Add the new entry to the data list\n",
    "                all_filtered_data.append(new_entry)\n",
    "\n",
    "                # Add the TOC data with indentation\n",
    "                for item in filtered_data:\n",
    "                    indent = \"  \" * (item[0] - 1)  # Create indentation based on the heading level\n",
    "                    entry = f\"{indent}{item[1]}\"  # Use the heading text\n",
    "                    all_filtered_data.append(entry)\n",
    "\n",
    "    # Write the data to the output file\n",
    "    with open(output_file, 'w', encoding=\"utf-8\") as file:\n",
    "        for entry in all_filtered_data:\n",
    "            file.write(entry + \"\\n\")\n",
    "\n",
    "    print(\"Filtered data has been saved to\", output_file)\n",
    "\n",
    "# Input and output folder paths\n",
    "input_folder = r\"D:\\CIS Intern\\Books\"\n",
    "output_file = 'D:/CIS Intern/Books/filtered_data.txt'\n",
    "\n",
    "# List of supported PDF file extensions\n",
    "supported_extensions = ['.pdf']\n",
    "\n",
    "# Call the function to process PDFs in the input folder\n",
    "process_pdfs_in_folder(input_folder, supported_extensions, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e301e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-3.15.2-py3-none-any.whl (271 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in d:\\anaconda\\lib\\site-packages (from pypdf) (4.1.1)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-3.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3034b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"D:\\CIS Intern\\Books\\Hands_on_Machine_Learning_with_Scikit_Le.pdf\")\n",
    "text = \"\"\n",
    "for i in range(10):\n",
    "    page = reader.pages[i]\n",
    "    text += page.extract_text() + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea66bf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAurélien GéronHands-on Machine Learning with\\nScikit-Learn, Keras, and\\nTensorFlow\\nConcepts, Tools, and Techniques to\\nBuild Intelligent SystemsSECOND EDITION\\nBoston Farnham Sebastopol Tokyo Beijing Boston Farnham Sebastopol Tokyo Beijing\\n978-1-492-03264-9\\n[LSI]Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow\\nby Aurélien Géron\\nCopyright © 2019 O’Reilly Media. All rights reserved.\\nPrinted in the United States of America.\\nPublished by O’Reilly Media, Inc. , 1005 Gravenstein Highway North, Sebastopol, CA 95472.\\nO’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are\\nalso available for most titles ( http://oreilly.com ). For more information, contact our corporate/institutional\\nsales department: 800-998-9938 or corporate@oreilly.com .\\nEditor:  Nicole Tache\\nInterior Designer:  David FutatoCover Designer:  Karen Montgomery\\nIllustrator:  Rebecca Demarest\\nJune 2019:  Second Edition\\nRevision History for the Early Release\\n2018-11-05: First Release\\n2019-01-24: Second Release\\nSee http://oreilly.com/catalog/errata.csp?isbn=9781492032649  for release details.\\nThe O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Hands-on Machine Learning with\\nScikit-Learn, Keras, and TensorFlow , the cover image, and related trade dress are trademarks of O’Reilly\\nMedia, Inc.\\nWhile the publisher and the author have used good faith efforts to ensure that the information and\\ninstructions contained in this work are accurate, the publisher and the author disclaim all responsibility\\nfor errors or omissions, including without limitation responsibility for damages resulting from the use of\\nor reliance on this work. Use of the information and instructions contained in this work is at your own\\nrisk. If any code samples or other technology this work contains or describes is subject to open source\\nlicenses or the intellectual property rights of others, it is your responsibility to ensure that your use\\nthereof complies with such licenses and/or rights.\\nTable of Contents\\n1.The Machine Learning Landscape. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  9\\nWhat Is Machine Learning?                                                                                           10\\nWhy Use Machine Learning?                                                                                         10\\nTypes of Machine Learning Systems                                                                             13\\nSupervised/Unsupervised Learning                                                                           14\\nBatch and Online Learning                                                                                         21\\nInstance-Based Versus Model-Based Learning                                                        24\\nMain Challenges of Machine Learning                                                                         30\\nInsufficient Quantity of Training Data                                                                      30\\nNonrepresentative Training Data                                                                               32\\nPoor-Quality Data                                                                                                        33\\nIrrelevant Features                                                                                                        33\\nOverfitting the Training Data                                                                                     34\\nUnderfitting the Training Data                                                                                  36\\nStepping Back                                                                                                               36\\nTesting and Validating                                                                                                     37\\nExercises                                                                                                                            39\\n2.End-to-End Machine Learning Project. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  41\\nWorking with Real Data                                                                                                  41\\nLook at the Big Picture                                                                                                    43\\nFrame the Problem                                                                                                       43\\nSelect a Performance Measure                                                                                    45\\nCheck the Assumptions                                                                                               48\\nGet the Data                                                                                                                      48\\nCreate the Workspace                                                                                                  48\\nDownload the Data                                                                                                      51\\nTake a Quick Look at the Data Structure                                                                  53\\niii\\nCreate a Test Set                                                                                                            57\\nDiscover and Visualize the Data to Gain Insights                                                       61\\nVisualizing Geographical Data                                                                                   62\\nLooking for Correlations                                                                                             64\\nExperimenting with Attribute Combinations                                                          67\\nPrepare the Data for Machine Learning Algorithms                                                  68\\nData Cleaning                                                                                                               69\\nHandling Text and Categorical Attributes                                                                71\\nCustom Transformers                                                                                                  73\\nFeature Scaling                                                                                                              74\\nTransformation Pipelines                                                                                            75\\nSelect and Train a Model                                                                                                 77\\nTraining and Evaluating on the Training Set                                                           77\\nBetter Evaluation Using Cross-Validation                                                                78\\nFine-Tune Y our Model                                                                                                    81\\nGrid Search                                                                                                                    81\\nRandomized Search                                                                                                     83\\nEnsemble Methods                                                                                                       84\\nAnalyze the Best Models and Their Errors                                                               84\\nEvaluate Y our System on the Test Set                                                                        85\\nLaunch, Monitor, and Maintain Y our System                                                              86\\nTry It Out!                                                                                                                         87\\nExercises                                                                                                                            87\\n3.Classification. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  89\\nMNIST                                                                                                                               89\\nTraining a Binary Classifier                                                                                            92\\nPerformance Measures                                                                                                    92\\nMeasuring Accuracy Using Cross-Validation                                                          93\\nConfusion Matrix                                                                                                         94\\nPrecision and Recall                                                                                                     96\\nPrecision/Recall Tradeoff                                                                                            97\\nThe ROC Curve                                                                                                          101\\nMulticlass Classification                                                                                               104\\nError Analysis                                                                                                                 106\\nMultilabel Classification                                                                                               110\\nMultioutput Classification                                                                                            111\\nExercises                                                                                                                          112\\n4.Training Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  115\\nLinear Regression                                                                                                           116\\nThe Normal Equation                                                                                                118\\niv | Table of Contents\\nComputational Complexity                                                                                      121\\nGradient Descent                                                                                                           121\\nBatch Gradient Descent                                                                                             125\\nStochastic Gradient Descent                                                                                     128\\nMini-batch Gradient Descent                                                                                   130\\nPolynomial Regression                                                                                                  132\\nLearning Curves                                                                                                             134\\nRegularized Linear Models                                                                                           138\\nRidge Regression                                                                                                        138\\nLasso Regression                                                                                                        141\\nElastic Net                                                                                                                    143\\nEarly Stopping                                                                                                            144\\nLogistic Regression                                                                                                        145\\nEstimating Probabilities                                                                                            145\\nTraining and Cost Function                                                                                      147\\nDecision Boundaries                                                                                                  148\\nSoftmax Regression                                                                                                    151\\nExercises                                                                                                                          155\\n5.Support Vector Machines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  157\\nLinear SVM Classification                                                                                            157\\nSoft Margin Classification                                                                                         158\\nNonlinear SVM Classification                                                                                     161\\nPolynomial Kernel                                                                                                      162\\nAdding Similarity Features                                                                                       163\\nGaussian RBF Kernel                                                                                                 164\\nComputational Complexity                                                                                      165\\nSVM Regression                                                                                                             166\\nUnder the Hood                                                                                                             168\\nDecision Function and Predictions                                                                         168\\nTraining Objective                                                                                                      169\\nQuadratic Programming                                                                                           171\\nThe Dual Problem                                                                                                      172\\nKernelized SVM                                                                                                         173\\nOnline SVMs                                                                                                               176\\nExercises                                                                                                                          177\\n6.Decision Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  179\\nTraining and Visualizing a Decision Tree                                                                  179\\nMaking Predictions                                                                                                       181\\nEstimating Class Probabilities                                                                                      183\\nThe CART Training Algorithm                                                                                   183\\nTable of Contents | v\\nComputational Complexity                                                                                          184\\nGini Impurity or Entropy?                                                                                           184\\nRegularization Hyperparameters                                                                                 185\\nRegression                                                                                                                       187\\nInstability                                                                                                                        189\\nExercises                                                                                                                          190\\n7.Ensemble Learning and Random Forests. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  193\\nVoting Classifiers                                                                                                           193\\nBagging and Pasting                                                                                                      196\\nBagging and Pasting in Scikit-Learn                                                                       198\\nOut-of-Bag Evaluation                                                                                              199\\nRandom Patches and Random Subspaces                                                                  200\\nRandom Forests                                                                                                             201\\nExtra-Trees                                                                                                                  202\\nFeature Importance                                                                                                    202\\nBoosting                                                                                                                          203\\nAdaBoost                                                                                                                     204\\nGradient Boosting                                                                                                      207\\nStacking                                                                                                                           212\\nExercises                                                                                                                          215\\n8.Dimensionality Reduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  217\\nThe Curse of Dimensionality                                                                                       218\\nMain Approaches for Dimensionality Reduction                                                     219\\nProjection                                                                                                                    219\\nManifold Learning                                                                                                     222\\nPCA                                                                                                                                  223\\nPreserving the Variance                                                                                             223\\nPrincipal Components                                                                                               224\\nProjecting Down to d Dimensions                                                                          225\\nUsing Scikit-Learn                                                                                                      226\\nExplained Variance Ratio                                                                                          226\\nChoosing the Right Number of Dimensions                                                          227\\nPCA for Compression                                                                                               228\\nRandomized PCA                                                                                                       229\\nIncremental PCA                                                                                                        229\\nKernel PCA                                                                                                                     230\\nSelecting a Kernel and Tuning Hyperparameters                                                  231\\nLLE                                                                                                                                   233\\nOther Dimensionality Reduction Techniques                                                       235\\nExercises                                                                                                                          236\\nvi | Table of Contents\\n9.Unsupervised Learning Techniques. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  239\\nClustering                                                                                                                        240\\nK-Means                                                                                                                      242\\nLimits of K-Means                                                                                                      252\\nUsing clustering for image segmentation                                                               253\\nUsing Clustering for Preprocessing                                                                         254\\nUsing Clustering for Semi-Supervised Learning                                                   256\\nDBSCAN                                                                                                                     258\\nOther Clustering Algorithms                                                                                   261\\nGaussian Mixtures                                                                                                         262\\nAnomaly Detection using Gaussian Mixtures                                                       268\\nSelecting the Number of Clusters                                                                            269\\nBayesian Gaussian Mixture Models                                                                         272\\nOther Anomaly Detection and Novelty Detection Algorithms                          276\\nTable of Contents | vii\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17f1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
