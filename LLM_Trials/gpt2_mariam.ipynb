{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GPT-2 Fine-Tuning","metadata":{}},{"cell_type":"markdown","source":"#### This is the code I wrote at the company, but I think it would be nice to share it here, so I post it.\n\n#### With this data, we will fine tune GPT-2 to make a sentence generation model. \n\n#### This code is for AI beginners.","metadata":{}},{"cell_type":"markdown","source":"## Step 1. Data preprocessing","metadata":{}},{"cell_type":"markdown","source":"#### the data contains unnecessary newlines, tags, and URLs it will be necessary to remove them before preprocessing.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-09-06T14:45:32.595878Z","iopub.execute_input":"2023-09-06T14:45:32.596301Z","iopub.status.idle":"2023-09-06T14:45:32.601372Z","shell.execute_reply.started":"2023-09-06T14:45:32.596266Z","shell.execute_reply":"2023-09-06T14:45:32.600114Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def cleaning(s):\n    s = str(s)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W,\\s',' ',s)\n    s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+',' ',s)\n    s = re.sub('[!@#$_]', '', s)\n    s = s.replace(\"co\",\"\")\n    s = s.replace(\"https\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    return s","metadata":{"execution":{"iopub.status.busy":"2023-09-06T14:45:34.403848Z","iopub.execute_input":"2023-09-06T14:45:34.404277Z","iopub.status.idle":"2023-09-06T14:45:34.411742Z","shell.execute_reply.started":"2023-09-06T14:45:34.404242Z","shell.execute_reply":"2023-09-06T14:45:34.410613Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv(\"Articles.csv\", encoding=\"ISO-8859-1\") \n# df = df.dropna()\n# text_data = open('Articles.txt', 'w')\n# for idx, item in df.iterrows():\n#   article = cleaning(item[\"Article\"])\n#   text_data.write(article)\n# text_data.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2. Model Training","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-09-06T14:45:39.670410Z","iopub.execute_input":"2023-09-06T14:45:39.671216Z","iopub.status.idle":"2023-09-06T14:46:08.061389Z","shell.execute_reply.started":"2023-09-06T14:45:39.671160Z","shell.execute_reply":"2023-09-06T14:46:08.059660Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.3.17)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.59.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TextDataset, DataCollatorForLanguageModeling\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-09-06T14:46:08.064139Z","iopub.execute_input":"2023-09-06T14:46:08.064694Z","iopub.status.idle":"2023-09-06T14:46:08.071395Z","shell.execute_reply.started":"2023-09-06T14:46:08.064639Z","shell.execute_reply":"2023-09-06T14:46:08.069957Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def load_dataset(file_path, tokenizer, block_size = 128):\n    dataset = TextDataset(\n        tokenizer = tokenizer,\n        file_path = file_path,\n        block_size = block_size,\n    )\n    return dataset\n\n\ndef load_data_collator(tokenizer, mlm = False):\n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, \n        mlm=mlm,\n    )\n    return data_collator\n\n\ndef train(train_file_path,model_name,\n          output_dir,\n          overwrite_output_dir,\n          per_device_train_batch_size,\n          num_train_epochs,\n          save_steps):\n  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n  train_dataset = load_dataset(train_file_path, tokenizer)\n  data_collator = load_data_collator(tokenizer)\n\n  tokenizer.save_pretrained(output_dir)\n      \n  model = GPT2LMHeadModel.from_pretrained(model_name)\n\n  model.save_pretrained(output_dir)\n\n  training_args = TrainingArguments(\n          output_dir=output_dir,\n          overwrite_output_dir=overwrite_output_dir,\n          per_device_train_batch_size=per_device_train_batch_size,\n          num_train_epochs=num_train_epochs,\n      )\n\n  trainer = Trainer(\n          model=model,\n          args=training_args,\n          data_collator=data_collator,\n          train_dataset=train_dataset,\n  )\n      \n  trainer.train()\n  trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T14:46:08.075540Z","iopub.execute_input":"2023-09-06T14:46:08.076035Z","iopub.status.idle":"2023-09-06T14:46:08.092236Z","shell.execute_reply.started":"2023-09-06T14:46:08.075996Z","shell.execute_reply":"2023-09-06T14:46:08.090670Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# you need to set parameters \ntrain_file_path = \"C:/Users/Mariam Barakat/Desktop/work/CIS_LLM/Git_hub/LLM_Research/Data Preprocessing/book_corpus_output.txt\"\nmodel_name = 'gpt2'\noutput_dir = 'C:/Users/Mariam Barakat/Desktop/work/CIS_LLM/Git_hub/LLM_Research/Data Preprocessing/results'\noverwrite_output_dir = False\nper_device_train_batch_size = 8\nnum_train_epochs = 5.0\nsave_steps = 500","metadata":{"execution":{"iopub.status.busy":"2023-09-06T14:46:08.094013Z","iopub.execute_input":"2023-09-06T14:46:08.094397Z","iopub.status.idle":"2023-09-06T14:46:08.113372Z","shell.execute_reply.started":"2023-09-06T14:46:08.094360Z","shell.execute_reply":"2023-09-06T14:46:08.112154Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# It takes about 30 minutes to train in colab.\ntrain(\n    train_file_path=train_file_path,\n    model_name=model_name,\n    output_dir=output_dir,\n    overwrite_output_dir=overwrite_output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    num_train_epochs=num_train_epochs,\n    save_steps=save_steps\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T14:46:08.114954Z","iopub.execute_input":"2023-09-06T14:46:08.115443Z","iopub.status.idle":"2023-09-06T14:46:28.233721Z","shell.execute_reply.started":"2023-09-06T14:46:08.115384Z","shell.execute_reply":"2023-09-06T14:46:28.231841Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-592574aa9826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msave_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n","\u001b[0;32m<ipython-input-14-d8b5e3211eb2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_file_path, model_name, output_dir, overwrite_output_dir, per_device_train_batch_size, num_train_epochs, save_steps)\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           save_steps):\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1668\u001b[0m                         \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                         \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m                         \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m                     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1171\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         )\n\u001b[1;32m   1175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m                     raise ValueError(\n\u001b[0;32m-> 1389\u001b[0;31m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                     )\n","\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."],"ename":"ValueError","evalue":"Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.","output_type":"error"}]},{"cell_type":"markdown","source":"## Step 3. Inference","metadata":{}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(model_path):\n    model = GPT2LMHeadModel.from_pretrained(model_path)\n    return model\n\n\ndef load_tokenizer(tokenizer_path):\n    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n    return tokenizer\n\n\ndef generate_text(sequence, max_length):\n    model_path = \"/content/drive/MyDrive/result\"\n    model = load_model(model_path)\n    tokenizer = load_tokenizer(model_path)\n    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n    final_outputs = model.generate(\n        ids,\n        do_sample=True,\n        max_length=max_length,\n        pad_token_id=model.config.eos_token_id,\n        top_k=50,\n        top_p=0.95,\n    )\n    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence = input() \nmax_len = int(input()) \ngenerate_text(sequence, max_len) ","metadata":{},"execution_count":null,"outputs":[]}]}